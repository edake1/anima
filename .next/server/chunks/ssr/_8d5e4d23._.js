module.exports=[35112,(a,b,c)=>{"use strict";b.exports=a.r(42602).vendored["react-ssr"].ReactDOM},69203,a=>{"use strict";let b=[{id:"agi-by-2027",title:"AGI by 2027",description:"AI systems achieve human-level general intelligence across all cognitive domains by 2027.",category:"agi-timeline",probability:.25,probabilityDistribution:[{year:2025,probability:.05},{year:2026,probability:.15},{year:2027,probability:.25},{year:2028,probability:.35},{year:2029,probability:.45},{year:2030,probability:.55}],timeframe:{earliest:2025,expected:2027,latest:2035},sources:[{id:"metaculus-agi",type:"prediction-market",title:"Metaculus AGI Question",url:"https://metaculus.com/questions/5121/date-of-artificial-general-intelligence/",credibility:85}],relatedPredictions:["asi-timeline","agi-by-2030"],lastUpdated:"2024-12-01",communityVotes:{agree:15420,disagree:8230,total:23650}},{id:"agi-by-2030",title:"AGI by 2030",description:"AI systems achieve human-level general intelligence by 2030.",category:"agi-timeline",probability:.55,probabilityDistribution:[{year:2025,probability:.05},{year:2026,probability:.12},{year:2027,probability:.22},{year:2028,probability:.35},{year:2029,probability:.48},{year:2030,probability:.55},{year:2031,probability:.65},{year:2032,probability:.72}],timeframe:{earliest:2025,expected:2030,latest:2040},sources:[{id:"metaculus-agi-2030",type:"prediction-market",title:"Metaculus AGI 2030",credibility:85},{id:"expert-survey-2023",type:"paper",title:"Expert Survey on AGI Timeline",credibility:80}],relatedPredictions:["agi-by-2027","asi-timeline"],lastUpdated:"2024-12-01",communityVotes:{agree:28500,disagree:12300,total:40800}},{id:"asi-timeline",title:"ASI by 2035",description:"Artificial Superintelligence - AI that dramatically exceeds human intelligence in all domains - emerges within a decade of AGI.",category:"asi-timeline",probability:.35,probabilityDistribution:[{year:2030,probability:.1},{year:2032,probability:.2},{year:2035,probability:.35},{year:2040,probability:.55},{year:2045,probability:.7}],timeframe:{earliest:2028,expected:2035,latest:2050},sources:[{id:"metaculus-asi",type:"prediction-market",title:"Metaculus ASI Question",credibility:80},{id:"kurzweil-singularity",type:"book",title:"The Singularity Is Near",credibility:70}],relatedPredictions:["agi-by-2027","intelligence-explosion"],lastUpdated:"2024-12-01",communityVotes:{agree:11200,disagree:18900,total:30100}},{id:"alignment-success",title:"AI Alignment Success",description:"Technical alignment problem is solved - AI systems reliably pursue intended goals without harmful misalignment.",category:"alignment-success",probability:.45,timeframe:{earliest:2025,expected:2030,latest:2040},sources:[{id:"alignment-survey",type:"paper",title:"AI Alignment Research Survey",credibility:75}],relatedPredictions:["agi-by-2030","existential-risk"],lastUpdated:"2024-11-15",communityVotes:{agree:18500,disagree:14200,total:32700}},{id:"existential-risk",title:"AI Existential Catastrophe",description:"AI causes severe harm to humanity at a civilizational scale, potentially including human extinction.",category:"alignment-success",probability:.12,timeframe:{earliest:2025,expected:2035,latest:2100},sources:[{id:"xrisk-survey",type:"paper",title:"Existential Risk from AI Survey",credibility:70},{id:"hinton-warning",type:"interview",title:"Hinton AI Warning",credibility:85}],relatedPredictions:["alignment-success","asi-timeline"],lastUpdated:"2024-12-01",communityVotes:{agree:8500,disagree:32100,total:40600}},{id:"economic-disruption",title:"Mass Labor Displacement by 2030",description:"AI automation displaces 30%+ of current jobs within this decade, requiring major economic restructuring.",category:"economic-impact",probability:.55,timeframe:{earliest:2025,expected:2028,latest:2032},sources:[{id:"goldman-sachs-report",type:"article",title:"Goldman Sachs AI Jobs Report",credibility:80},{id:"mckinsey-automation",type:"article",title:"McKinsey Automation Report",credibility:80}],relatedPredictions:["agi-by-2030","ubi-adoption"],lastUpdated:"2024-10-01",communityVotes:{agree:28900,disagree:15600,total:44500}},{id:"ubi-adoption",title:"Universal Basic Income Adopted",description:"Major economies implement universal basic income in response to AI-driven job displacement.",category:"economic-impact",probability:.4,timeframe:{earliest:2028,expected:2035,latest:2050},sources:[{id:"ubi-research",type:"article",title:"UBI Policy Research",credibility:70}],relatedPredictions:["economic-disruption","agi-by-2030"],lastUpdated:"2024-09-01",communityVotes:{agree:22100,disagree:19800,total:41900}},{id:"reasoning-breakthrough",title:"System 2 Reasoning Achieved",description:'AI systems achieve reliable "System 2" thinking - deliberate, logical reasoning beyond pattern matching.',category:"capability-breakthrough",probability:.65,timeframe:{earliest:2024,expected:2026,latest:2028},sources:[{id:"reasoning-research",type:"paper",title:"AI Reasoning Research",credibility:80}],relatedPredictions:["agi-by-2027","o1-breakthrough"],lastUpdated:"2024-11-01",communityVotes:{agree:35200,disagree:8900,total:44100}},{id:"multimodal-native",title:"Native Multimodal Understanding",description:"AI systems natively understand and generate across text, image, video, audio, and code as unified representations.",category:"capability-breakthrough",probability:.75,timeframe:{earliest:2024,expected:2025,latest:2027},sources:[{id:"gpt4o-demo",type:"article",title:"GPT-4o Demo",credibility:90},{id:"gemini-multimodal",type:"article",title:"Gemini Multimodal",credibility:85}],relatedPredictions:["reasoning-breakthrough"],lastUpdated:"2024-12-01",communityVotes:{agree:42100,disagree:5200,total:47300}},{id:"world-models",title:"Robust World Models",description:"AI systems develop rich internal models of how the physical and social world works, enabling better planning and prediction.",category:"capability-breakthrough",probability:.5,timeframe:{earliest:2025,expected:2027,latest:2030},sources:[{id:"world-model-paper",type:"paper",title:"World Models in AI",credibility:75},{id:"lecun-world-model",type:"interview",title:"LeCun on World Models",credibility:85}],relatedPredictions:["reasoning-breakthrough","agi-by-2027"],lastUpdated:"2024-10-15",communityVotes:{agree:26800,disagree:14200,total:41e3}},{id:"agent-autonomy",title:"Fully Autonomous AI Agents",description:"AI agents can independently complete complex, multi-step tasks over extended time periods with minimal human oversight.",category:"capability-breakthrough",probability:.7,timeframe:{earliest:2024,expected:2026,latest:2028},sources:[{id:"agent-research",type:"paper",title:"Autonomous Agent Research",credibility:75}],relatedPredictions:["multi-agent-systems","economic-disruption"],lastUpdated:"2024-11-20",communityVotes:{agree:33100,disagree:9800,total:42900}},{id:"multi-agent-systems",title:"Collaborative Multi-Agent Systems",description:"Networks of specialized AI agents work together to solve problems beyond any single agent's capability.",category:"capability-breakthrough",probability:.8,timeframe:{earliest:2024,expected:2025,latest:2027},sources:[{id:"multi-agent-paper",type:"paper",title:"Multi-Agent Systems Research",credibility:80}],relatedPredictions:["agent-autonomy","agi-by-2027"],lastUpdated:"2024-12-01",communityVotes:{agree:38500,disagree:6200,total:44700}},{id:"ai-regulation",title:"Comprehensive AI Regulation",description:"Major governments implement comprehensive AI safety and governance regulations.",category:"regulation",probability:.85,timeframe:{earliest:2024,expected:2026,latest:2028},sources:[{id:"eu-ai-act",type:"article",title:"EU AI Act",credibility:95},{id:"us-ai-order",type:"article",title:"US AI Executive Order",credibility:90}],relatedPredictions:["alignment-success"],lastUpdated:"2024-11-01",communityVotes:{agree:45200,disagree:3100,total:48300}},{id:"compute-growth",title:"1000x Compute Growth by 2030",description:"AI training compute continues exponential growth, achieving 1000x improvement from 2024 levels.",category:"capability-breakthrough",probability:.7,timeframe:{earliest:2026,expected:2030,latest:2032},sources:[{id:"epoch-compute",type:"article",title:"Epoch AI Compute Trends",credibility:85}],relatedPredictions:["agi-by-2030","economic-disruption"],lastUpdated:"2024-10-01",communityVotes:{agree:29800,disagree:12100,total:41900}}];function c(a){return b.find(b=>b.id===a)}a.s(["getPredictionById",()=>c,"predictions",0,b])},73570,a=>{"use strict";let b=(0,a.i(70106).default)("triangle-alert",[["path",{d:"m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3",key:"wmoenq"}],["path",{d:"M12 9v4",key:"juzpu7"}],["path",{d:"M12 17h.01",key:"p32p05"}]]);a.s(["AlertTriangle",()=>b],73570)},86304,a=>{"use strict";var b=a.i(87924),c=a.i(11011),d=a.i(187),e=a.i(68114);let f=(0,d.cva)("inline-flex items-center justify-center rounded-md border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden",{variants:{variant:{default:"border-transparent bg-primary text-primary-foreground [a&]:hover:bg-primary/90",secondary:"border-transparent bg-secondary text-secondary-foreground [a&]:hover:bg-secondary/90",destructive:"border-transparent bg-destructive text-white [a&]:hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60",outline:"text-foreground [a&]:hover:bg-accent [a&]:hover:text-accent-foreground"}},defaultVariants:{variant:"default"}});function g({className:a,variant:d,asChild:g=!1,...h}){let i=g?c.Slot:"span";return(0,b.jsx)(i,{"data-slot":"badge",className:(0,e.cn)(f({variant:d}),a),...h})}a.s(["Badge",()=>g])},52495,a=>{"use strict";let b=(0,a.i(70106).default)("external-link",[["path",{d:"M15 3h6v6",key:"1q9fwt"}],["path",{d:"M10 14 21 3",key:"gplh6r"}],["path",{d:"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6",key:"a6xqqp"}]]);a.s(["ExternalLink",()=>b],52495)},210,a=>{"use strict";let b=(0,a.i(70106).default)("arrow-left",[["path",{d:"m12 19-7-7 7-7",key:"1l729n"}],["path",{d:"M19 12H5",key:"x3x0zl"}]]);a.s(["ArrowLeft",()=>b],210)},24669,a=>{"use strict";let b=(0,a.i(70106).default)("trending-up",[["path",{d:"M16 7h6v6",key:"box55l"}],["path",{d:"m22 7-8.5 8.5-5-5L2 17",key:"1t1m79"}]]);a.s(["TrendingUp",()=>b],24669)},76893,a=>{"use strict";let b=[{id:"sam-altman",name:"Sam Altman",title:"CEO",organization:"OpenAI",stance:"optimist",credibility:95,avatar:"/experts/altman.png",biography:"Sam Altman is the CEO of OpenAI, one of the leading AI research laboratories. He has been instrumental in the development of GPT models and advocates for responsible AGI development.",predictions:[{id:"altman-agi-2025",expertId:"sam-altman",prediction:"AGI (defined as smarter than the smartest human) will arrive within 2 years",topic:"agi",timeframe:{start:2025,end:2027},madeAt:"2024-01-15",confidence:"high",status:"pending",source:{id:"altman-davos-2024",type:"interview",title:"World Economic Forum Davos 2024",url:"https://www.weforum.org/events/world-economic-forum-annual-meeting-2024",publishDate:"2024-01-15",credibility:95}},{id:"altman-superintelligence",expertId:"sam-altman",prediction:"Superintelligence could arrive within a decade after AGI",topic:"asi",timeframe:{start:2027,end:2037},madeAt:"2023-09-01",confidence:"medium",status:"pending",source:{id:"openai-superintelligence-2023",type:"article",title:"Governance of Superintelligence",url:"https://openai.com/blog/governance-of-superintelligence",publishDate:"2023-05-23",credibility:95}}],quotes:[{id:"altman-quote-1",text:"If you define AGI as smarter than the smartest human, I think it's probably next year, within two years.",context:"Interview at World Economic Forum",date:"2024-01-15",source:{id:"altman-davos-q",type:"interview",title:"WEF Davos 2024",credibility:95}}],socialLinks:{twitter:"https://twitter.com/sama",linkedin:"https://linkedin.com/in/samaltman"},sources:[{id:"openai-about",type:"article",title:"About OpenAI",url:"https://openai.com/about",credibility:95}]},{id:"ray-kurzweil",name:"Ray Kurzweil",title:"Director of Engineering",organization:"Google",stance:"optimist",credibility:90,avatar:"/experts/kurzweil.png",biography:"Ray Kurzweil is a futurist, author, and Director of Engineering at Google. He is known for his predictions about technological singularity and has a track record of accurate technological forecasts.",predictions:[{id:"kurzweil-agi-2029",expertId:"ray-kurzweil",prediction:"AGI will pass the Turing Test by 2029",topic:"agi",timeframe:{start:2029,end:2029},madeAt:"1999-01-01",confidence:"high",status:"pending",source:{id:"kurzweil-book-1999",type:"book",title:"The Age of Spiritual Machines",authors:["Ray Kurzweil"],publishDate:"1999-01-01",credibility:90}},{id:"kurzweil-singularity",expertId:"ray-kurzweil",prediction:"The Singularity will occur in 2045",topic:"asi",timeframe:{start:2045,end:2045},madeAt:"2005-01-01",confidence:"high",status:"pending",source:{id:"kurzweil-singularity-book",type:"book",title:"The Singularity Is Near",authors:["Ray Kurzweil"],publishDate:"2005-01-01",credibility:90}}],quotes:[{id:"kurzweil-quote-1",text:"By 2029, computers will have human-level intelligence.",context:"Prediction from The Age of Spiritual Machines",date:"1999-01-01",source:{id:"kurzweil-book-q",type:"book",title:"The Age of Spiritual Machines",credibility:90}}],sources:[{id:"kurzweil-wiki",type:"article",title:"Ray Kurzweil Wikipedia",url:"https://en.wikipedia.org/wiki/Ray_Kurzweil",credibility:80}]},{id:"demis-hassabis",name:"Demis Hassabis",title:"CEO",organization:"Google DeepMind",stance:"optimist",credibility:97,avatar:"/experts/hassabis.png",biography:"Demis Hassabis is the CEO of Google DeepMind and a Nobel laureate. He led the development of AlphaGo, AlphaFold, and other breakthrough AI systems.",predictions:[{id:"hassabis-agi-timeline",expertId:"demis-hassabis",prediction:"AGI could be possible within this decade with current rate of progress",topic:"agi",timeframe:{start:2025,end:2030},madeAt:"2024-03-15",confidence:"medium",status:"pending",source:{id:"hassabis-interview-2024",type:"interview",title:"BBC Interview March 2024",publishDate:"2024-03-15",credibility:95}}],quotes:[{id:"hassabis-quote-1",text:"We're on an exponential curve... I think we're talking years, not decades.",context:"On AGI timeline",date:"2024-03-15",source:{id:"hassabis-bbc",type:"interview",title:"BBC Interview",credibility:95}}],sources:[{id:"deepmind-about",type:"article",title:"DeepMind About",url:"https://deepmind.com/about",credibility:97}]},{id:"geoffrey-hinton",name:"Geoffrey Hinton",title:"Nobel Laureate, Professor Emeritus",organization:"University of Toronto",stance:"cautious",credibility:99,avatar:"/experts/hinton.png",biography:'Geoffrey Hinton is one of the "Godfathers of AI" and a Nobel Prize laureate. He left Google in 2023 to speak freely about AI risks.',predictions:[{id:"hinton-agi-rapid",expertId:"geoffrey-hinton",prediction:"AGI could arrive much sooner than expected, possibly within 5 years",topic:"agi",timeframe:{start:2023,end:2028},madeAt:"2023-05-01",confidence:"high",status:"pending",source:{id:"hinton-resignation",type:"interview",title:"CBS News Interview",publishDate:"2023-05-01",credibility:95}},{id:"hinton-extinction-risk",expertId:"geoffrey-hinton",prediction:"AI could pose extinction-level risks if not properly aligned",topic:"alignment",timeframe:{start:2024,end:2050},madeAt:"2023-05-01",confidence:"high",status:"pending",source:{id:"hinton-risk-warning",type:"article",title:'"Godfather of AI" leaves Google',url:"https://www.cbsnews.com/news/godfather-of-artificial-intelligence-geoffrey-hinton-leaves-google/",publishDate:"2023-05-01",credibility:95}}],quotes:[{id:"hinton-quote-1",text:"It is hard to see how you can prevent the bad actors from using it for bad things.",context:"On AI risks",date:"2023-05-01",source:{id:"hinton-cbs",type:"interview",title:"CBS Interview",credibility:95}},{id:"hinton-quote-2",text:"I console myself with the normal excuse: If I hadn't done it, somebody else would have.",context:"On his role in AI development",date:"2023-05-01",source:{id:"hinton-nyt",type:"article",title:"New York Times Interview",credibility:95}}],sources:[{id:"hinton-wiki",type:"article",title:"Geoffrey Hinton Wikipedia",url:"https://en.wikipedia.org/wiki/Geoffrey_Hinton",credibility:90}]},{id:"yoshua-bengio",name:"Yoshua Bengio",title:"Professor, Scientific Director",organization:"Mila, University of Montreal",stance:"cautious",credibility:98,avatar:"/experts/bengio.png",biography:'Yoshua Bengio is a Turing Award winner and one of the "Godfathers of AI". He founded Mila and advocates for responsible AI development.',predictions:[{id:"bengio-agi-timeline",expertId:"yoshua-bengio",prediction:"AGI could arrive within years, not decades",topic:"agi",timeframe:{start:2025,end:2030},madeAt:"2023-06-01",confidence:"medium",status:"pending",source:{id:"bengio-testimony",type:"interview",title:"Congressional Testimony",publishDate:"2023-06-01",credibility:95}},{id:"bengio-safety-priority",expertId:"yoshua-bengio",prediction:"AI safety research must be prioritized alongside capability development",topic:"alignment",timeframe:{start:2023,end:2030},madeAt:"2023-06-01",confidence:"high",status:"pending",source:{id:"bengio-safety-article",type:"article",title:"AI Safety Statement",publishDate:"2023-06-01",credibility:95}}],quotes:[{id:"bengio-quote-1",text:"We need to be very careful about how we deploy these systems... we need to think about the long-term consequences.",context:"On AI development",date:"2023-06-01",source:{id:"bengio-congress",type:"interview",title:"Congressional Hearing",credibility:95}}],sources:[{id:"bengio-mila",type:"article",title:"Mila - Yoshua Bengio",url:"https://mila.quebec/en/yoshua-bengio/",credibility:95}]},{id:"yann-lecun",name:"Yann LeCun",title:"Chief AI Scientist",organization:"Meta AI",stance:"skeptic",credibility:98,avatar:"/experts/lecun.png",biography:"Yann LeCun is a Turing Award winner, Chief AI Scientist at Meta, and professor at NYU. He is known for his work on convolutional neural networks and maintains a skeptical view of imminent AGI.",predictions:[{id:"lecun-no-agi-soon",expertId:"yann-lecun",prediction:"Current LLMs will not lead to AGI; fundamentally new architectures needed",topic:"agi",timeframe:{start:2024,end:2050},madeAt:"2024-01-01",confidence:"high",status:"pending",source:{id:"lecun-llm-critique",type:"article",title:"LeCun on LLMs",url:"https://twitter.com/ylecun",publishDate:"2024-01-01",credibility:90}},{id:"lecun-cat-intelligence",expertId:"yann-lecun",prediction:"Current AI is far from cat-level intelligence in terms of understanding the physical world",topic:"agi",timeframe:{start:2024,end:2035},madeAt:"2023-12-01",confidence:"high",status:"pending",source:{id:"lecun-cat-quote",type:"interview",title:"Various interviews",publishDate:"2023-12-01",credibility:90}}],quotes:[{id:"lecun-quote-1",text:"LLMs have a very limited understanding of the underlying reality... They don't understand the physical world.",context:"On LLM limitations",date:"2024-01-15",source:{id:"lecun-talk",type:"interview",title:"Public Talk",credibility:90}},{id:"lecun-quote-2",text:"We are still far from human-level AI.",context:"On AGI timeline",date:"2024-02-01",source:{id:"lecun-twitter",type:"tweet",title:"Twitter/X",credibility:85}}],sources:[{id:"lecun-meta",type:"article",title:"Meta AI - Yann LeCun",url:"https://ai.meta.com/people/yann-lecun/",credibility:95}]},{id:"andrew-ng",name:"Andrew Ng",title:"Founder",organization:"DeepLearning.AI",stance:"skeptic",credibility:95,avatar:"/experts/ng.png",biography:"Andrew Ng is a pioneer in online education and AI. He founded Google Brain, was Baidu's Chief Scientist, and created Coursera and DeepLearning.AI.",predictions:[{id:"ng-agi-timeline",expertId:"andrew-ng",prediction:"AGI is still decades away; current AI progress is overhyped",topic:"agi",timeframe:{start:2040,end:2060},madeAt:"2023-07-01",confidence:"medium",status:"pending",source:{id:"ng-aghi-view",type:"interview",title:"Interview on AI Hype",publishDate:"2023-07-01",credibility:90}},{id:"ng-worry-wrong",expertId:"andrew-ng",prediction:"Current AI fears are overblown; focus should be on near-term issues",topic:"alignment",timeframe:{start:2023,end:2030},madeAt:"2023-06-01",confidence:"high",status:"pending",source:{id:"ng-fears",type:"article",title:"Andrew Ng on AI Fears",publishDate:"2023-06-01",credibility:90}}],quotes:[{id:"ng-quote-1",text:"I think worrying about AI turning evil is like worrying about overpopulation on Mars.",context:"On AI existential risk",date:"2023-06-01",source:{id:"ng-mars",type:"interview",title:"Interview",credibility:90}}],sources:[{id:"ng-deeplearning",type:"article",title:"DeepLearning.AI",url:"https://www.deeplearning.ai/",credibility:95}]},{id:"dario-amodei",name:"Dario Amodei",title:"CEO",organization:"Anthropic",stance:"neutral",credibility:96,avatar:"/experts/amodei.png",biography:"Dario Amodei is the CEO of Anthropic, an AI safety company. He previously led AI safety at OpenAI and advocates for responsible AI development.",predictions:[{id:"amodei-agi-powerful",expertId:"dario-amodei",prediction:"AI systems will become extremely powerful within years; safety research is critical",topic:"agi",timeframe:{start:2025,end:2030},madeAt:"2023-09-01",confidence:"high",status:"pending",source:{id:"amodei-anthropic",type:"article",title:"Anthropic Mission",url:"https://www.anthropic.com/about",publishDate:"2023-09-01",credibility:95}},{id:"amodei-constitutional",expertId:"dario-amodei",prediction:"Constitutional AI and similar approaches can help align AI systems",topic:"alignment",timeframe:{start:2023,end:2028},madeAt:"2023-09-01",confidence:"medium",status:"pending",source:{id:"amodei-constitutional",type:"paper",title:"Constitutional AI",authors:["Anthropic"],publishDate:"2022-12-01",credibility:95}}],quotes:[{id:"amodei-quote-1",text:"We think AI will be a transformative technology, and we want to build it in a way that's safe and beneficial.",context:"On Anthropic's mission",date:"2023-09-01",source:{id:"amodei-interview",type:"interview",title:"Interview",credibility:95}}],sources:[{id:"anthropic-about",type:"article",title:"Anthropic About",url:"https://www.anthropic.com/about",credibility:96}]},{id:"ilya-sutskever",name:"Ilya Sutskever",title:"Co-founder & Former Chief Scientist",organization:"OpenAI / SSI",stance:"neutral",credibility:97,avatar:"/experts/sutskever.png",biography:"Ilya Sutskever is a co-founder of OpenAI and former Chief Scientist. He left in 2024 to found SSI (Safe Superintelligence Inc). He is one of the most influential AI researchers.",predictions:[{id:"sutskever-superintelligence",expertId:"ilya-sutskever",prediction:"Superintelligence is possible within years to decades; safety is paramount",topic:"asi",timeframe:{start:2025,end:2035},madeAt:"2024-07-01",confidence:"medium",status:"pending",source:{id:"sutskever-ssi",type:"article",title:"SSI Inc Announcement",publishDate:"2024-07-01",credibility:95}}],quotes:[{id:"sutskever-quote-1",text:"Our mission is to build safe superintelligence.",context:"On founding SSI",date:"2024-07-01",source:{id:"sutskever-ssi-q",type:"article",title:"SSI Inc",credibility:95}}],sources:[{id:"sutskever-openai",type:"article",title:"OpenAI Research",credibility:95}]}];function c(a){return b.filter(b=>b.stance===a)}function d(a){return b.find(b=>b.id===a)}a.s(["experts",0,b,"getExpertById",()=>d,"getExpertsByStance",()=>c])},16201,a=>{"use strict";let b=(0,a.i(70106).default)("circle-check-big",[["path",{d:"M21.801 10A10 10 0 1 1 17 3.335",key:"yps3ct"}],["path",{d:"m9 11 3 3L22 4",key:"1pflzl"}]]);a.s(["CheckCircle",()=>b],16201)}];

//# sourceMappingURL=_8d5e4d23._.js.map